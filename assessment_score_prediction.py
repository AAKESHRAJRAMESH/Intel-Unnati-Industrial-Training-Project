import pandas as pd
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer, PolynomialFeatures
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import warnings

warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# --- 1. Load Data ---
file_path = 'Assessment_Score.csv'
try:
    df = pd.read_csv(file_path)
    print(f"Successfully loaded dataset: {file_path}")
    print("Original Dataset Shape:", df.shape)
except FileNotFoundError:
    print(f"Error: Dataset file not found at {file_path}")
    print("Please ensure the file generated by the second script is in the correct directory.")
    exit()
except Exception as e:
    print(f"An error occurred loading the CSV: {e}")
    exit()

# --- Remove Visualization-Specific '_Num' Columns ---
print("\nChecking for and removing visualization-specific '_Num' columns...")
num_cols_to_drop_viz = ['Student_Level_Num', 'Material_Level_Num', 'Course_Level_Num', 'Consistency_Num']
cols_actually_dropped_viz = [col for col in num_cols_to_drop_viz if col in df.columns]
if cols_actually_dropped_viz:
    df = df.drop(columns=cols_actually_dropped_viz)
    print(f"Removed visualization columns: {cols_actually_dropped_viz}")
else:
    print("No visualization-specific '_Num' columns found to remove.")
print("Dataset Shape after removing viz columns:", df.shape)

# --- 2. Define Target and Features ---
target = 'Assessment Score'
potential_other_drop_cols = ['Health Description']
cols_to_drop_total = [target] + [col for col in potential_other_drop_cols if col in df.columns]

if target not in df.columns:
    print(f"\nError: Target column '{target}' not found in the dataframe.")
    exit()

try:
    y = df[target]
    X = df.drop(columns=cols_to_drop_total)
    print("\nTarget and features defined.")
    print(f"Features ('X') Shape: {X.shape}")
except KeyError as e:
    print(f"\nError selecting features/target: Missing column - {e}")
    exit()
except Exception as e:
    print(f"An unexpected error occurred defining X and y: {e}")
    exit()

# --- 3. Identify Feature Types ---
try:
    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()
    print("\nIdentified Numerical Features:", numerical_features)
    print("Identified Categorical Features:", categorical_features)
    if len(numerical_features) + len(categorical_features) != X.shape[1]:
        print("\nWarning: Not all feature columns were identified as numerical or categorical.")
except Exception as e:
    print(f"An error occurred identifying feature types: {e}")
    exit()

# --- 4. Split Data into Training and Testing Sets ---
try:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print(f"\nData split into training ({X_train.shape[0]} samples) and testing ({X_test.shape[0]} samples).")
except Exception as e:
    print(f"An error occurred during data splitting: {e}")
    exit()

# --- 5. Preprocessing and Model Pipeline (Improved XGBoost) ---
numerical_transformer = Pipeline(steps=[
    ('power', PowerTransformer(method='yeo-johnson')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='passthrough'
)

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('poly_features', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),
    ('model', XGBRegressor(random_state=42, objective='reg:squarederror',
                          n_estimators=400, learning_rate=0.02, max_depth=7,
                          subsample=0.65, colsample_bytree=0.65, gamma=0.25,
                          reg_alpha=0.1, reg_lambda=2.5, min_child_weight=3,
                          colsample_bynode=0.8)) #added colsample_bynode.
])

# --- 6. Train the Model ---
print("\nTraining the XGBoost model...")
try:
    pipeline.fit(X_train, y_train)
    print("Model training completed.")
except Exception as e:
    print(f"\nAn error occurred during model training: {e}")
    exit()

# --- 7. Evaluate the Model on the Test Set ---
print("\n--- Evaluating Model on Test Set ---")
try:
    y_pred = pipeline.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"Mean Squared Error (MSE): {mse:.4f}")
    print(f"Root Mean Squared Error (RMSE): {mse**0.5:.4f}")
    print(f"R-squared (R2): {r2:.4f}")
except Exception as e:
    print(f"An error occurred during model evaluation: {e}")
    exit()

# --- 8. Predict on New Data ---
new_student_data = {
    'Age': [16, 10, 22],
    'Gender': ['Male', 'Female', 'Male'],
    'Parent Occupation': ['Engineer', 'Artist', 'Teacher'],
    'Earning Class': ['High', 'Low', 'Middle'],
    'Level of Student': ['Advanced', 'Beginner', 'Intermediate'],
    'Level of Course': ['Advanced', 'Intermediate', 'Intermediate'],
    'Course Name': ['Physics', 'Art', 'Math'],
    'Time per Day (hrs)': [3.5, 1.0, 2.5],
    'Material Level': ['Advanced', 'Beginner', 'Intermediate'],
    'IQ': [125, 95, 110],
    'Consistency': ['Regular', 'Irregular', 'Regular'],
    'Health': [5, 3, 4],
}

input_df = pd.DataFrame(new_student_data)

print("\n--- Predicting Assessment Scores for New Student Data ---")
print("Input Data:")
print(input_df)

try:
    predicted_scores = pipeline.predict(input_df)
    print("\nPredicted Assessment Score(s):")
    input_df['Predicted Score'] = predicted_scores
    for index, row in input_df.iterrows():
        print(f"  Student {index + 1} (Input: {row['Level of Student']}, {row['Consistency']}, IQ {row['IQ']}) -> Predicted Score: {row['Predicted Score']:.2f}")

except Exception as e:
    print(f"\nAn error occurred during prediction on new data: {e}")

print("\n--- Prediction Script Completed ---")
